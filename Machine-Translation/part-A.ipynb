{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Imports"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T18:04:29.240518Z","iopub.status.busy":"2024-04-06T18:04:29.240155Z","iopub.status.idle":"2024-04-06T18:04:35.148546Z","shell.execute_reply":"2024-04-06T18:04:35.147697Z","shell.execute_reply.started":"2024-04-06T18:04:29.240490Z"},"trusted":true},"outputs":[],"source":["import torch\n","import math\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","from datasets import load_dataset\n","from torch.nn import Transformer\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","from timeit import default_timer as timer\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader"]},{"cell_type":"markdown","metadata":{},"source":["# Pre-Training"]},{"cell_type":"markdown","metadata":{},"source":["## Setting up the vocabulary"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T18:04:35.157154Z","iopub.status.busy":"2024-04-06T18:04:35.156802Z","iopub.status.idle":"2024-04-06T18:04:35.165073Z","shell.execute_reply":"2024-04-06T18:04:35.164212Z","shell.execute_reply.started":"2024-04-06T18:04:35.157122Z"},"trusted":true},"outputs":[],"source":["#Environment variables\n","SRC_LANGUAGE = 'de'\n","TGT_LANGUAGE = 'en'\n","UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n","special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T18:04:35.167922Z","iopub.status.busy":"2024-04-06T18:04:35.167289Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Using the latest cached version of the dataset since wmt16 couldn't be found on the Hugging Face Hub\n","Found the latest cached dataset configuration 'de-en' at C:\\Users\\Aditya Ahuja\\.cache\\huggingface\\datasets\\wmt16\\de-en\\0.0.0\\41d8a4013aa1489f28fea60ec0932af246086482 (last modified on Wed Apr  3 18:15:35 2024).\n"]}],"source":["train_data = load_dataset(\"wmt16\", \"de-en\", split=\"train[:50000]\")\n","val_data = load_dataset(\"wmt16\", \"de-en\", split=\"validation\")\n","test_data = load_dataset(\"wmt16\", \"de-en\", split=\"test\")\n","de_tokenizer = get_tokenizer(\"spacy\", language=\"de_core_news_sm\")\n","en_tokenizer = get_tokenizer(\"spacy\", language=\"en_core_web_sm\")"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[],"source":["class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, data, source_lang, target_lang):\n","        self.data = data\n","        self.source_lang = source_lang\n","        self.target_lang = target_lang\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        source_sentence = self.data[idx]['translation'][self.source_lang]\n","        target_sentence = self.data[idx]['translation'][self.target_lang]\n","        return source_sentence, target_sentence"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[],"source":["train_dataset = CustomDataset(train_data, SRC_LANGUAGE, TGT_LANGUAGE)\n","val_dataset = CustomDataset(val_data, SRC_LANGUAGE, TGT_LANGUAGE)\n","test_dataset = CustomDataset(test_data, SRC_LANGUAGE, TGT_LANGUAGE)"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["def yield_tokens(data_iter, language):\n","\n","    for data_sample in data_iter:\n","        if (language == \"en\"):\n","            yield en_tokenizer(data_sample[\"translation\"][\"en\"])\n","        else:\n","            yield en_tokenizer(data_sample[\"translation\"][\"de\"])\n","\n","\n","de_vocab = build_vocab_from_iterator(yield_tokens(train_data, SRC_LANGUAGE), specials=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"])\n","en_vocab = build_vocab_from_iterator(yield_tokens(train_data, TGT_LANGUAGE), specials=[\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"])\n","de_vocab.set_default_index(de_vocab[\"<unk>\"])\n","en_vocab.set_default_index(en_vocab[\"<unk>\"])"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[],"source":["token_transform = {}\n","vocab_transform = {}\n","token_transform[SRC_LANGUAGE] = de_tokenizer\n","token_transform[TGT_LANGUAGE] = en_tokenizer\n","vocab_transform[SRC_LANGUAGE] = de_vocab\n","vocab_transform[TGT_LANGUAGE] = en_vocab\n","vocab_transform[SRC_LANGUAGE].set_default_index(vocab_transform[SRC_LANGUAGE][\"<unk>\"])\n","vocab_transform[TGT_LANGUAGE].set_default_index(vocab_transform[TGT_LANGUAGE][\"<unk>\"])"]},{"cell_type":"markdown","metadata":{},"source":["## Helper Classes"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[],"source":["class PositionalEncoding(nn.Module):\n","    def __init__(self,\n","                 emb_size: int,\n","                 dropout: float,\n","                 maxlen: int = 5000):\n","        super(PositionalEncoding, self).__init__()\n","        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n","        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n","        pos_embedding = torch.zeros((maxlen, emb_size))\n","        pos_embedding[:, 0::2] = torch.sin(pos * den)\n","        pos_embedding[:, 1::2] = torch.cos(pos * den)\n","        pos_embedding = pos_embedding.unsqueeze(-2)\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.register_buffer('pos_embedding', pos_embedding)\n","\n","    def forward(self, token_embedding: torch.Tensor):\n","        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[],"source":["class TokenEmbedding(nn.Module):\n","    def __init__(self, vocab_size: int, emb_size):\n","        super(TokenEmbedding, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, emb_size)\n","        self.emb_size = emb_size\n","\n","    def forward(self, tokens: torch.Tensor):\n","        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[],"source":["class Seq2SeqTransformer(nn.Module):\n","    def __init__(\n","        self,\n","        num_encoder_layers: int,\n","        num_decoder_layers: int,\n","        emb_size: int,\n","        nhead: int,\n","        src_vocab_size: int,\n","        tgt_vocab_size: int,\n","        dim_feedforward: int = 512,\n","        dropout: float = 0.1,\n","    ):\n","        super(Seq2SeqTransformer, self).__init__()\n","        self.transformer = Transformer(\n","            d_model=emb_size,\n","            nhead=nhead,\n","            num_encoder_layers=num_encoder_layers,\n","            num_decoder_layers=num_decoder_layers,\n","            dim_feedforward=dim_feedforward,\n","            dropout=dropout,\n","        )\n","        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n","        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n","        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n","        self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)\n","\n","    def forward(\n","        self,\n","        src: torch.Tensor,\n","        trg: torch.Tensor,\n","        src_mask: torch.Tensor,\n","        tgt_mask: torch.Tensor,\n","        src_padding_mask: torch.Tensor,\n","        tgt_padding_mask: torch.Tensor,\n","        memory_key_padding_mask: torch.Tensor,\n","    ):\n","        src_emb = self.positional_encoding(self.src_tok_emb(src))\n","        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n","        outs = self.transformer(\n","            src_emb,\n","            tgt_emb,\n","            src_mask,\n","            tgt_mask,\n","            None,\n","            src_padding_mask,\n","            tgt_padding_mask,\n","            memory_key_padding_mask,\n","        )\n","        return self.generator(outs)\n","\n","    def encode(self, src: torch.Tensor, src_mask: torch.Tensor):\n","        return self.transformer.encoder(\n","            self.positional_encoding(self.src_tok_emb(src)), src_mask\n","        )\n","\n","    def decode(self, tgt: torch.Tensor, memory: torch.Tensor, tgt_mask: torch.Tensor):\n","        return self.transformer.decoder(\n","            self.positional_encoding(self.tgt_tok_emb(tgt)), memory, tgt_mask\n","        )"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[],"source":["def generate_square_subsequent_mask(sz):\n","    mask = (torch.triu(torch.ones((sz, sz), device = device)) == 1).transpose(0, 1)\n","    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","    return mask\n","\n","def create_mask(src, tgt):\n","    src_seq_len = src.shape[0]\n","    tgt_seq_len = tgt.shape[0]\n","\n","    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n","    src_mask = torch.zeros((src_seq_len, src_seq_len),device=device).type(torch.bool)\n","\n","    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n","    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n","    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Miniconda\\envs\\amlenv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"]}],"source":["torch.manual_seed(0)\n","\n","SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n","TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n","EMB_SIZE = 512\n","NHEAD = 8\n","FFN_HID_DIM = 512\n","BATCH_SIZE = 32\n","NUM_ENCODER_LAYERS = 3\n","NUM_DECODER_LAYERS = 3\n","\n","transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n","                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n","\n","for p in transformer.parameters():\n","    if p.dim() > 1:\n","        nn.init.xavier_uniform_(p)\n","\n","transformer = transformer.to(device)\n","\n"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'transformer' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(ignore_index\u001b[38;5;241m=\u001b[39mPAD_IDX)\n\u001b[1;32m----> 3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(\u001b[43mtransformer\u001b[49m\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, betas\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m0.98\u001b[39m), eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-9\u001b[39m)\n","\u001b[1;31mNameError\u001b[0m: name 'transformer' is not defined"]}],"source":["loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n","\n","optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def sequential_transforms(*transforms):\n","    def func(txt_input):\n","        for transform in transforms:\n","            txt_input = transform(txt_input)\n","        return txt_input\n","    return func\n","\n","def tensor_transform(token_ids: list[int]):\n","    return torch.cat((torch.tensor([BOS_IDX]),\n","                      torch.tensor(token_ids),\n","                      torch.tensor([EOS_IDX])))\n","\n","text_transform = {}\n","for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n","    text_transform[ln] = sequential_transforms(token_transform[ln],\n","                                               vocab_transform[ln],\n","                                               tensor_transform) \n","\n","\n","def collate_fn(batch):\n","    src_batch, tgt_batch = [], []\n","    for src_sample, tgt_sample in batch:\n","        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n","        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n","    \n","\n","    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n","    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n","    return src_batch, tgt_batch"]},{"cell_type":"markdown","metadata":{},"source":["# Training the model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def train_epoch(model, optimizer):\n","    model.train()\n","    losses = 0\n","    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n","\n","    for src, tgt in train_dataloader:\n","        src = src.to(device)\n","        tgt = tgt.to(device)\n","\n","        tgt_input = tgt[:-1, :]\n","\n","        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n","\n","        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n","\n","        optimizer.zero_grad()\n","\n","        tgt_out = tgt[1:, :]\n","        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n","        loss.backward()\n","\n","        optimizer.step()\n","        losses += loss.item()\n","\n","    return losses / len(list(train_dataloader))\n","\n","\n","def evaluate(model):\n","    model.eval()\n","    losses = 0\n","\n","    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n","\n","    for src, tgt in val_dataloader:\n","        src = src.to(device)\n","        tgt = tgt.to(device)\n","\n","        tgt_input = tgt[:-1, :]\n","\n","        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n","\n","        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n","\n","        tgt_out = tgt[1:, :]\n","        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n","        losses += loss.item()\n","\n","    return losses / len(list(val_dataloader))"]},{"cell_type":"code","execution_count":158,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T15:56:50.799396Z","iopub.status.busy":"2024-04-06T15:56:50.798721Z","iopub.status.idle":"2024-04-06T16:54:56.485322Z","shell.execute_reply":"2024-04-06T16:54:56.484339Z","shell.execute_reply.started":"2024-04-06T15:56:50.799351Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 1, Train loss: 5.398, Val loss: 6.526, Epoch time = 171.834s\n","Epoch: 2, Train loss: 4.576, Val loss: 6.256, Epoch time = 171.736s\n","Epoch: 3, Train loss: 4.126, Val loss: 6.117, Epoch time = 171.802s\n","Epoch: 4, Train loss: 3.769, Val loss: 6.033, Epoch time = 171.850s\n","Epoch: 5, Train loss: 3.476, Val loss: 6.031, Epoch time = 171.706s\n","Epoch: 6, Train loss: 3.229, Val loss: 5.987, Epoch time = 171.718s\n","Epoch: 7, Train loss: 3.020, Val loss: 5.987, Epoch time = 171.683s\n","Epoch: 8, Train loss: 2.839, Val loss: 5.965, Epoch time = 171.602s\n","Epoch: 9, Train loss: 2.683, Val loss: 5.967, Epoch time = 171.500s\n","Epoch: 10, Train loss: 2.545, Val loss: 5.934, Epoch time = 171.815s\n","Epoch: 11, Train loss: 2.421, Val loss: 5.922, Epoch time = 171.622s\n","Epoch: 12, Train loss: 2.308, Val loss: 5.987, Epoch time = 171.706s\n","Epoch: 13, Train loss: 2.206, Val loss: 6.088, Epoch time = 171.633s\n","Epoch: 14, Train loss: 2.113, Val loss: 6.182, Epoch time = 171.678s\n","Epoch: 15, Train loss: 2.025, Val loss: 6.251, Epoch time = 171.619s\n","Epoch: 16, Train loss: 1.941, Val loss: 6.368, Epoch time = 171.517s\n","Epoch: 17, Train loss: 1.864, Val loss: 6.300, Epoch time = 170.691s\n","Epoch: 18, Train loss: 1.791, Val loss: 6.283, Epoch time = 171.057s\n","Epoch: 19, Train loss: 1.722, Val loss: 6.334, Epoch time = 170.963s\n","Epoch: 20, Train loss: 1.655, Val loss: 6.335, Epoch time = 170.675s\n"]}],"source":["NUM_EPOCHS = 20\n","train_losses = []\n","val_losses = []\n","for epoch in range(1, NUM_EPOCHS+1):\n","    start_time = timer()\n","    train_loss = train_epoch(transformer, optimizer)\n","    train_losses.append(train_loss)\n","    end_time = timer()\n","    val_loss = evaluate(transformer)\n","    val_losses.append(val_loss)\n","    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))"]},{"cell_type":"code","execution_count":164,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:08:10.116655Z","iopub.status.busy":"2024-04-06T17:08:10.116239Z","iopub.status.idle":"2024-04-06T17:08:10.122137Z","shell.execute_reply":"2024-04-06T17:08:10.121070Z","shell.execute_reply.started":"2024-04-06T17:08:10.116626Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[5.39832918810219, 4.5760343588855275, 4.125646812520726, 3.769066235840664, 3.476328090758028, 3.229339740097866, 3.0197367679592286, 2.839209471844132, 2.6834240710971757, 2.5447975946250665, 2.4214571353646326, 2.308028604194131, 2.2064599975972166, 2.11307049857754, 2.0254748427783995, 1.9406443995996232, 1.8644984820982773, 1.7912119138111156, 1.7221313121985413, 1.6550585926913788]\n","[6.526368625023785, 6.255807427799001, 6.116526568637175, 6.033405787804547, 6.03099860163296, 5.987043692785151, 5.986844511593089, 5.964711217319264, 5.967441839330337, 5.933810626759248, 5.921976159600651, 5.986951337141149, 6.087898601503933, 6.181596503538244, 6.250875785070307, 6.368396324269912, 6.29969328992507, 6.283229421166813, 6.33449400172514, 6.335193753242493]\n"]}],"source":["print(train_losses)\n","print(val_losses)"]},{"cell_type":"code","execution_count":185,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:25:10.076854Z","iopub.status.busy":"2024-04-06T17:25:10.076233Z","iopub.status.idle":"2024-04-06T17:25:10.958525Z","shell.execute_reply":"2024-04-06T17:25:10.957546Z","shell.execute_reply.started":"2024-04-06T17:25:10.076823Z"},"trusted":true},"outputs":[],"source":["# torch.save(transformer.state_dict(),\"/kaggle/transformer.pth\" )"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n","                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["transformer.load_state_dict(torch.load(\"/kaggle/transformer.pth\"))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["blue = evaluate.load(\"bleu\")\n","meteor = evaluate.load(\"meteor\")\n","bert = evaluate.load(\"bertscore\")\n","\n","def postprocess_text(preds, labels):\n","    preds = [pred.strip() for pred in preds]\n","    labels = [[label.strip()] for label in labels]\n","\n","    return preds, labels\n","\n","def compute_metrics(eval_preds):\n","    preds, labels = eval_preds\n","    if isinstance(preds, tuple):\n","        preds = preds[0]\n","    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","                          \n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n","\n","    result_bleu = blue.compute(predictions=decoded_preds, references=decoded_labels)\n","    result_meteor = meteor.compute(predictions=decoded_preds, references=decoded_labels)\n","    result_BERT = bert.compute(predictions=decoded_preds, references=decoded_labels, model_type=\"distilbert-base-uncased\")\n","    result = {\"bleu\": result_bleu['bleu'], \n","              \"bleu_precision\": sum(result_bleu['precisions'])/len(result_bleu['precisions']),\n","              \"meteor\":result_meteor['meteor'],\n","              \"BERT_precision\":sum(result_BERT['precision'])/len(result_BERT['precision']),\n","              \"BERT_recall\":sum(result_BERT['recall'])/len(result_BERT['recall']),\n","              \"BERT_F1\":sum(result_BERT['f1'])/len(result_BERT['f1'])}\n","    return result"]},{"cell_type":"code","execution_count":182,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:18:43.838304Z","iopub.status.busy":"2024-04-06T17:18:43.837862Z","iopub.status.idle":"2024-04-06T17:18:43.852507Z","shell.execute_reply":"2024-04-06T17:18:43.851568Z","shell.execute_reply.started":"2024-04-06T17:18:43.838275Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>                            <div id=\"91bea37b-5670-47f0-8116-3ba1832274ec\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"91bea37b-5670-47f0-8116-3ba1832274ec\")) {                    Plotly.newPlot(                        \"91bea37b-5670-47f0-8116-3ba1832274ec\",                        [{\"mode\":\"lines+markers\",\"name\":\"Train Losses\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\"y\":[5.39832918810219,4.5760343588855275,4.125646812520726,3.769066235840664,3.476328090758028,3.229339740097866,3.0197367679592286,2.839209471844132,2.6834240710971757,2.5447975946250665,2.4214571353646326,2.308028604194131,2.2064599975972166,2.11307049857754,2.0254748427783995,1.9406443995996232,1.8644984820982773,1.7912119138111156,1.7221313121985413,1.6550585926913788],\"type\":\"scatter\"},{\"mode\":\"lines+markers\",\"name\":\"Validation Losses\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\"y\":[6.526368625023785,6.255807427799001,6.116526568637175,6.033405787804547,6.03099860163296,5.987043692785151,5.986844511593089,5.964711217319264,5.967441839330337,5.933810626759248,5.921976159600651,5.986951337141149,6.087898601503933,6.181596503538244,6.250875785070307,6.368396324269912,6.29969328992507,6.283229421166813,6.33449400172514,6.335193753242493],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('91bea37b-5670-47f0-8116-3ba1832274ec');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                });            </script>        </div>"]},"metadata":{},"output_type":"display_data"}],"source":["import pandas as pd\n","import plotly.graph_objects as go\n","\n","# Create a DataFrame\n","df = pd.DataFrame({\n","    'x': range(1, len(train_losses) + 1),\n","    'Train Losses': train_losses,\n","    'Validation Losses': val_losses\n","})\n","\n","# Create a figure\n","fig = go.Figure()\n","\n","# Add traces for each line with markers\n","for col in df.columns[1:]:\n","    fig.add_trace(go.Scatter(x=df['x'], y=df[col], mode='lines+markers', name=col))\n","\n","# Show the plot\n","fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = torch.load"]},{"cell_type":"code","execution_count":171,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T17:09:18.719705Z","iopub.status.busy":"2024-04-06T17:09:18.718804Z","iopub.status.idle":"2024-04-06T17:09:18.777291Z","shell.execute_reply":"2024-04-06T17:09:18.776185Z","shell.execute_reply.started":"2024-04-06T17:09:18.719669Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" I am in favour of this . \n"]}],"source":["# function to generate output sequence using greedy algorithm\n","def greedy_decode(model, src, src_mask, max_len, start_symbol):\n","    src = src.to(device)\n","    src_mask = src_mask.to(device)\n","\n","    memory = model.encode(src, src_mask)\n","    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n","    for i in range(max_len-1):\n","        memory = memory.to(device)\n","        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n","                    .type(torch.bool)).to(device)\n","        out = model.decode(ys, memory, tgt_mask)\n","        out = out.transpose(0, 1)\n","        prob = model.generator(out[:, -1])\n","        _, next_word = torch.max(prob, dim=1)\n","        next_word = next_word.item()\n","\n","        ys = torch.cat([ys,\n","                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n","        if next_word == EOS_IDX:\n","            break\n","    return ys\n","\n","\n","# actual function to translate input sentence into target language\n","def translate(model: torch.nn.Module, src_sentence: str):\n","    model.eval()\n","    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n","    num_tokens = src.shape[0]\n","    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n","    tgt_tokens = greedy_decode(\n","        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n","    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n","\n","print(translate(transformer, \"Hallo, ich bin hier\"))"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":4}
